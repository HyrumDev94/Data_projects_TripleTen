# Data Cleaning & Missing Data Visualization  

**Goal:**  
Prepare a raw dataset for reliable analysis by identifying, handling, and visualizing missing or inconsistent data.  

**Steps:**  
- Detected missing values, duplicates, and outliers  
- Applied imputation techniques and transformations  
- Visualized missing data patterns and post-cleaning results  
- Verified data integrity before downstream analysis  

**Outcome:**  
Produced a clean, consistent dataset ready for analysis and modeling, improving data quality and accuracy.  

**Skills Used:** pandas, NumPy, data preprocessing, visualization, exploratory data analysis  

**Files:**  
- `data_cleaning.ipynb`

<img width="885" height="537" alt="Screenshot 2025-10-20 at 3 23 24 PM" src="https://github.com/user-attachments/assets/b87eb231-1bc2-4c2b-8dbc-7eeadcf84452" />

<img width="888" height="449" alt="Screenshot 2025-10-20 at 3 22 53 PM" src="https://github.com/user-attachments/assets/9087b5e8-a1cd-4576-9499-18dc7deca454" />

## View Project: [Notebook](https://github.com/HyrumDev94/Data_projects_TripleTen/blob/main/data_cleaning/25ef8da9-6c14-4615-b68f-f7ceffea2b02%20(1).ipynb)

##  Future Improvements

- Automate the data cleaning workflow using Python scripts or a reproducible pipeline (e.g., Prefect or Airflow) to handle larger datasets efficiently.  
- Integrate automated quality checks and data validation (using libraries like `pandera` or `great_expectations`) to catch missing values or outliers before analysis.  
- Build a simple dashboard that visualizes cleaning metrics (e.g., missing data percentage or duplicates over time) to monitor data health interactively.
